{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "df=pd.read_csv(\"GA_JvsR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>corpus_year</th>\n",
       "      <th>query_source</th>\n",
       "      <th>query_year</th>\n",
       "      <th>query</th>\n",
       "      <th>query_topicID</th>\n",
       "      <th>best_match</th>\n",
       "      <th>best_match_score</th>\n",
       "      <th>best_match_topicID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2012</td>\n",
       "      <td>['sleep', 'relax', 'calm', 'night', 'help', 's...</td>\n",
       "      <td>0</td>\n",
       "      <td>['patient', 'anxiety', 'cognitive', 'treatment...</td>\n",
       "      <td>0.761707</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2012</td>\n",
       "      <td>['anyone_else', 'today', 'amount', 'coffee', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>['fear', 'sad', 'memory', 'social', 'previous'...</td>\n",
       "      <td>0.593093</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2012</td>\n",
       "      <td>['drive', 'tomorrow', 'test', 'exercise', 'app...</td>\n",
       "      <td>2</td>\n",
       "      <td>['anxiety', 'guide', 'find', 'face', 'scale', ...</td>\n",
       "      <td>0.694902</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2012</td>\n",
       "      <td>['guy', 'deal', 'one', 'interested', 'random',...</td>\n",
       "      <td>3</td>\n",
       "      <td>['fear', 'sad', 'memory', 'social', 'previous'...</td>\n",
       "      <td>0.557574</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2012</td>\n",
       "      <td>['alone', 'exist', 'somewhere', 'female', 'pre...</td>\n",
       "      <td>4</td>\n",
       "      <td>['single', 'nucleus', 'rat', 'apoptosis', 'neu...</td>\n",
       "      <td>0.606998</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2020</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2020</td>\n",
       "      <td>['stomach', 'better', 'change', 'trigger', 'mg...</td>\n",
       "      <td>30</td>\n",
       "      <td>['sleep', 'effect', 'response', 'increase', 'n...</td>\n",
       "      <td>0.591387</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2020</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2020</td>\n",
       "      <td>['world', 'head', 'tip', 'matter', 'situation'...</td>\n",
       "      <td>31</td>\n",
       "      <td>['cognitive', 'trait', 'performance', 'avoidan...</td>\n",
       "      <td>0.650616</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2020</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2020</td>\n",
       "      <td>['happen', 'realize', 'many', 'kind', 'somethi...</td>\n",
       "      <td>32</td>\n",
       "      <td>['sleep', 'effect', 'response', 'increase', 'n...</td>\n",
       "      <td>0.537414</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2020</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2020</td>\n",
       "      <td>['test', 'covid', 'remove', 'positive', 'paren...</td>\n",
       "      <td>33</td>\n",
       "      <td>['negative', 'self', 'relationship', 'individu...</td>\n",
       "      <td>0.629861</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2020</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2020</td>\n",
       "      <td>['tell', 'want', 'say', 'read', 'know', 'small...</td>\n",
       "      <td>34</td>\n",
       "      <td>['mdd', 'suicide', 'major_depressive', 'suicid...</td>\n",
       "      <td>0.510246</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1971 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        corpus  corpus_year query_source  query_year  \\\n",
       "0     Academic         2012       Reddit        2012   \n",
       "1     Academic         2012       Reddit        2012   \n",
       "2     Academic         2012       Reddit        2012   \n",
       "3     Academic         2012       Reddit        2012   \n",
       "4     Academic         2012       Reddit        2012   \n",
       "...        ...          ...          ...         ...   \n",
       "1966  Academic         2020       Reddit        2020   \n",
       "1967  Academic         2020       Reddit        2020   \n",
       "1968  Academic         2020       Reddit        2020   \n",
       "1969  Academic         2020       Reddit        2020   \n",
       "1970  Academic         2020       Reddit        2020   \n",
       "\n",
       "                                                  query  query_topicID  \\\n",
       "0     ['sleep', 'relax', 'calm', 'night', 'help', 's...              0   \n",
       "1     ['anyone_else', 'today', 'amount', 'coffee', '...              1   \n",
       "2     ['drive', 'tomorrow', 'test', 'exercise', 'app...              2   \n",
       "3     ['guy', 'deal', 'one', 'interested', 'random',...              3   \n",
       "4     ['alone', 'exist', 'somewhere', 'female', 'pre...              4   \n",
       "...                                                 ...            ...   \n",
       "1966  ['stomach', 'better', 'change', 'trigger', 'mg...             30   \n",
       "1967  ['world', 'head', 'tip', 'matter', 'situation'...             31   \n",
       "1968  ['happen', 'realize', 'many', 'kind', 'somethi...             32   \n",
       "1969  ['test', 'covid', 'remove', 'positive', 'paren...             33   \n",
       "1970  ['tell', 'want', 'say', 'read', 'know', 'small...             34   \n",
       "\n",
       "                                             best_match  best_match_score  \\\n",
       "0     ['patient', 'anxiety', 'cognitive', 'treatment...          0.761707   \n",
       "1     ['fear', 'sad', 'memory', 'social', 'previous'...          0.593093   \n",
       "2     ['anxiety', 'guide', 'find', 'face', 'scale', ...          0.694902   \n",
       "3     ['fear', 'sad', 'memory', 'social', 'previous'...          0.557574   \n",
       "4     ['single', 'nucleus', 'rat', 'apoptosis', 'neu...          0.606998   \n",
       "...                                                 ...               ...   \n",
       "1966  ['sleep', 'effect', 'response', 'increase', 'n...          0.591387   \n",
       "1967  ['cognitive', 'trait', 'performance', 'avoidan...          0.650616   \n",
       "1968  ['sleep', 'effect', 'response', 'increase', 'n...          0.537414   \n",
       "1969  ['negative', 'self', 'relationship', 'individu...          0.629861   \n",
       "1970  ['mdd', 'suicide', 'major_depressive', 'suicid...          0.510246   \n",
       "\n",
       "      best_match_topicID  \n",
       "0                      8  \n",
       "1                     18  \n",
       "2                     24  \n",
       "3                     18  \n",
       "4                     32  \n",
       "...                  ...  \n",
       "1966                   3  \n",
       "1967                   9  \n",
       "1968                   3  \n",
       "1969                  12  \n",
       "1970                  10  \n",
       "\n",
       "[1971 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "#Get the number of topics in one year\n",
    "df12=df[df['query_year']==2012]\n",
    "n12=max(df12['query_topicID'])\n",
    "print(n12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "df13=df[df['query_year']==2013]\n",
    "n13=max(df13['query_topicID'])\n",
    "print(n13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "df14=df[df['query_year']==2014]\n",
    "n14=max(df14['query_topicID'])\n",
    "print(n14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "df15=df[df['query_year']==2015]\n",
    "n15=max(df15['query_topicID'])\n",
    "print(n15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "df16=df[df['query_year']==2016]\n",
    "n16=max(df16['query_topicID'])\n",
    "print(n16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "df17=df[df['query_year']==2017]\n",
    "n17=max(df17['query_topicID'])\n",
    "print(n17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "df18=df[df['query_year']==2018]\n",
    "n18=max(df18['query_topicID'])\n",
    "print(n18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "df19=df[df['query_year']==2019]\n",
    "n19=max(df19['query_topicID'])\n",
    "print(n19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "df20=df[df['query_year']==2020]\n",
    "n20=max(df20['query_topicID'])\n",
    "print(n20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls12=[]\n",
    "ls13=[]\n",
    "ls14=[]\n",
    "ls15=[]\n",
    "ls16=[]\n",
    "ls17=[]\n",
    "ls18=[]\n",
    "ls19=[]\n",
    "ls20=[]\n",
    "for i in range(0,n):\n",
    "    if df['query_year'][i]==2012:\n",
    "        x=df['query_topicID'][i]\n",
    "        y=df['best_match_score'][i]\n",
    "        tup=(x,y)\n",
    "        #This tuple is of the form (topic_ID, highest score) for a given year\n",
    "        ls12.append(tup)\n",
    "        #This list stores all such tuples for one year\n",
    "    elif df['query_year'][i]==2013:\n",
    "        x=df['query_topicID'][i]\n",
    "        y=df['best_match_score'][i]\n",
    "        tup=(x,y)\n",
    "        ls13.append(tup)\n",
    "    elif df['query_year'][i]==2014:\n",
    "        x=df['query_topicID'][i]\n",
    "        y=df['best_match_score'][i]\n",
    "        tup=(x,y)\n",
    "        ls14.append(tup)\n",
    "    elif df['query_year'][i]==2015:\n",
    "        x=df['query_topicID'][i]\n",
    "        y=df['best_match_score'][i]\n",
    "        tup=(x,y)\n",
    "        ls15.append(tup)\n",
    "    elif df['query_year'][i]==2016:\n",
    "        x=df['query_topicID'][i]\n",
    "        y=df['best_match_score'][i]\n",
    "        tup=(x,y)\n",
    "        ls16.append(tup)\n",
    "    elif df['query_year'][i]==2017:\n",
    "        x=df['query_topicID'][i]\n",
    "        y=df['best_match_score'][i]\n",
    "        tup=(x,y)\n",
    "        ls17.append(tup)\n",
    "    elif df['query_year'][i]==2018:\n",
    "        x=df['query_topicID'][i]\n",
    "        y=df['best_match_score'][i]\n",
    "        tup=(x,y)\n",
    "        ls18.append(tup)\n",
    "    elif df['query_year'][i]==2019:\n",
    "        x=df['query_topicID'][i]\n",
    "        y=df['best_match_score'][i]\n",
    "        tup=(x,y)\n",
    "        ls19.append(tup)\n",
    "    elif df['query_year'][i]==2020:\n",
    "        x=df['query_topicID'][i]\n",
    "        y=df['best_match_score'][i]\n",
    "        tup=(x,y)\n",
    "        ls20.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.635540306568146), (1, 0.631395816802979), (2, 0.730427920818329), (3, 0.703975379467011), (4, 0.718698501586914), (5, 0.627431869506836), (6, 0.757065057754517), (7, 0.629390597343445), (8, 0.679049551486969), (9, 0.583821654319763), (10, 0.598224461078644), (11, 0.588795185089111), (12, 0.708298623561859), (13, 0.742399096488953), (14, 0.70017147064209), (15, 0.618593096733093), (16, 0.638533174991608), (17, 0.631402909755707), (18, 0.664270162582397), (0, 0.667408585548401), (1, 0.687953531742096), (2, 0.713820576667785), (3, 0.695944845676422), (4, 0.657252669334412), (5, 0.61995542049408), (6, 0.760728120803833), (7, 0.580750226974487), (8, 0.591945588588715), (9, 0.60331791639328), (10, 0.568686068058014), (11, 0.523378193378449), (12, 0.698269009590149), (13, 0.64979350566864), (14, 0.639692842960358), (15, 0.640653252601624), (16, 0.642999112606049), (17, 0.56647801399231), (18, 0.672764956951141), (0, 0.647639751434326), (1, 0.604557514190674), (2, 0.731281936168671), (3, 0.631771385669708), (4, 0.687377452850342), (5, 0.582602083683014), (6, 0.68838107585907), (7, 0.622886538505554), (8, 0.604414165019989), (9, 0.571274518966675), (10, 0.561638951301575), (11, 0.527130007743835), (12, 0.702937543392181), (13, 0.645847856998444), (14, 0.635216414928436), (15, 0.607167840003967), (16, 0.608625113964081), (17, 0.568730056285858), (18, 0.677369296550751), (0, 0.667490482330322), (1, 0.707330226898193), (2, 0.720039546489716), (3, 0.648772239685059), (4, 0.625877559185028), (5, 0.584702491760254), (6, 0.746155560016632), (7, 0.598268151283264), (8, 0.647352576255798), (9, 0.580492615699768), (10, 0.55498617887497), (11, 0.539223611354828), (12, 0.681459188461304), (13, 0.626876533031464), (14, 0.646805882453918), (15, 0.576440513134003), (16, 0.624154448509216), (17, 0.574976027011871), (18, 0.628986239433289), (0, 0.681447505950928), (1, 0.640540719032288), (2, 0.709885478019714), (3, 0.650833129882813), (4, 0.694121897220612), (5, 0.634745657444), (6, 0.690973281860352), (7, 0.563372731208801), (8, 0.583655595779419), (9, 0.568361699581146), (10, 0.540759563446045), (11, 0.543703138828278), (12, 0.716236650943756), (13, 0.631064593791962), (14, 0.591513574123383), (15, 0.668497741222382), (16, 0.612456977367401), (17, 0.611630439758301), (18, 0.635960102081299), (0, 0.645450711250305), (1, 0.59199470281601), (2, 0.725044786930084), (3, 0.668271541595459), (4, 0.655448913574219), (5, 0.580750644207001), (6, 0.789203763008118), (7, 0.616028010845184), (8, 0.714096605777741), (9, 0.562878549098969), (10, 0.544628024101257), (11, 0.564355969429016), (12, 0.688015162944794), (13, 0.673512816429138), (14, 0.629007399082184), (15, 0.699053764343262), (16, 0.599866509437561), (17, 0.56637454032898), (18, 0.649424910545349), (0, 0.6825932264328), (1, 0.612965703010559), (2, 0.692293524742126), (3, 0.629958212375641), (4, 0.646184325218201), (5, 0.594441950321198), (6, 0.70270562171936), (7, 0.583159446716309), (8, 0.665876865386963), (9, 0.529980957508087), (10, 0.586843430995941), (11, 0.523000597953796), (12, 0.675122141838074), (13, 0.633113563060761), (14, 0.590880274772644), (15, 0.708584129810333), (16, 0.600377321243286), (17, 0.550695300102234), (18, 0.63260805606842), (0, 0.662504017353058), (1, 0.611076295375824), (2, 0.688972175121307), (3, 0.661570549011231), (4, 0.668182194232941), (5, 0.609295904636383), (6, 0.757595360279083), (7, 0.595980703830719), (8, 0.499109089374542), (9, 0.530986189842224), (10, 0.561457276344299), (11, 0.492490470409393), (12, 0.665152132511139), (13, 0.622298657894135), (14, 0.595958054065704), (15, 0.641484975814819), (16, 0.627379775047302), (17, 0.569394886493683), (18, 0.639929533004761), (0, 0.69013774394989), (1, 0.634668052196503), (2, 0.683487713336945), (3, 0.687011241912842), (4, 0.756756842136383), (5, 0.605671107769012), (6, 0.703258633613586), (7, 0.585725009441376), (8, 0.588776290416718), (9, 0.51392525434494), (10, 0.525256812572479), (11, 0.540598511695862), (12, 0.690512716770172), (13, 0.628820061683655), (14, 0.556605696678162), (15, 0.685335516929626), (16, 0.638662219047546), (17, 0.526513278484345), (18, 0.642641127109528)]\n"
     ]
    }
   ],
   "source": [
    "print(ls13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.635540306568146), (0, 0.667408585548401), (0, 0.647639751434326), (0, 0.667490482330322), (0, 0.681447505950928), (0, 0.645450711250305), (0, 0.6825932264328), (0, 0.662504017353058), (0, 0.69013774394989)]\n"
     ]
    }
   ],
   "source": [
    "t0=[]\n",
    "l=len(ls13)\n",
    "for i in range(l):\n",
    "    if ls13[i][0]==0:\n",
    "        t0.append(ls13[i])\n",
    "print(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.69013774394989)\n"
     ]
    }
   ],
   "source": [
    "m=max(t0)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "row=df[df['best_match_score'] == m[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the highest score for a particular query by topic_ID number\n",
    "def get_best_score(ls,topic_ID):\n",
    "    t=[]\n",
    "    l=len(ls)\n",
    "    for i in range(l):\n",
    "        if ls[i][0]==topic_ID:\n",
    "            t.append(ls[i])\n",
    "    m=max(t)\n",
    "    #print(m)\n",
    "    row=df[df['best_match_score'] == m[1]]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     corpus  corpus_year query_source  query_year  \\\n",
      "0  Academic         2012       Reddit        2012   \n",
      "\n",
      "                                               query  query_topicID  \\\n",
      "0  ['sleep', 'relax', 'calm', 'night', 'help', 's...              0   \n",
      "\n",
      "                                          best_match  best_match_score  \\\n",
      "0  ['patient', 'anxiety', 'cognitive', 'treatment...          0.761707   \n",
      "\n",
      "   best_match_topicID  \n",
      "0                   8  \n"
     ]
    }
   ],
   "source": [
    "ans=get_best_score(ls12,0)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Dataframe to store the results\n",
    "output=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gap Analysis for 2012\n",
    "for val in range(n12):\n",
    "    op=get_best_score(ls12,val)\n",
    "    output=output.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gap Analysis for 2013\n",
    "for val in range(n13):\n",
    "    op=get_best_score(ls13,val)\n",
    "    output=output.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gap Analysis for 2014\n",
    "for val in range(n14):\n",
    "    op=get_best_score(ls14,val)\n",
    "    output=output.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gap Analysis for 2015\n",
    "for val in range(n15):\n",
    "    op=get_best_score(ls15,val)\n",
    "    output=output.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gap Analysis for 2016\n",
    "for val in range(n16):\n",
    "    op=get_best_score(ls16,val)\n",
    "    output=output.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gap Analysis for 2017\n",
    "for val in range(n17):\n",
    "    op=get_best_score(ls17,val)\n",
    "    output=output.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gap Analysis for 2018\n",
    "for val in range(n18):\n",
    "    op=get_best_score(ls18,val)\n",
    "    output=output.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gap Analysis for 2019\n",
    "for val in range(n19):\n",
    "    op=get_best_score(ls19,val)\n",
    "    output=output.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gap Analysis for 2020\n",
    "for val in range(n20):\n",
    "    op=get_best_score(ls20,val)\n",
    "    output=output.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>corpus_year</th>\n",
       "      <th>query_source</th>\n",
       "      <th>query_year</th>\n",
       "      <th>query</th>\n",
       "      <th>query_topicID</th>\n",
       "      <th>best_match</th>\n",
       "      <th>best_match_score</th>\n",
       "      <th>best_match_topicID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2012</td>\n",
       "      <td>['sleep', 'relax', 'calm', 'night', 'help', 's...</td>\n",
       "      <td>0</td>\n",
       "      <td>['patient', 'anxiety', 'cognitive', 'treatment...</td>\n",
       "      <td>0.761707</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2020</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2012</td>\n",
       "      <td>['anyone_else', 'today', 'amount', 'coffee', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>['cognitive', 'trait', 'performance', 'avoidan...</td>\n",
       "      <td>0.618855</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2013</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2012</td>\n",
       "      <td>['drive', 'tomorrow', 'test', 'exercise', 'app...</td>\n",
       "      <td>2</td>\n",
       "      <td>['phobia', 'life_event', 'depression', 'emerge...</td>\n",
       "      <td>0.711446</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2012</td>\n",
       "      <td>['guy', 'deal', 'one', 'interested', 'random',...</td>\n",
       "      <td>3</td>\n",
       "      <td>['social', 'sad', 'change', 'personality', 'co...</td>\n",
       "      <td>0.564091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>Academic</td>\n",
       "      <td>2017</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2012</td>\n",
       "      <td>['alone', 'exist', 'somewhere', 'female', 'pre...</td>\n",
       "      <td>4</td>\n",
       "      <td>['mental', 'health', 'self', 'network', 'repor...</td>\n",
       "      <td>0.609496</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        corpus  corpus_year query_source  query_year  \\\n",
       "0     Academic         2012       Reddit        2012   \n",
       "1753  Academic         2020       Reddit        2012   \n",
       "221   Academic         2013       Reddit        2012   \n",
       "660   Academic         2015       Reddit        2012   \n",
       "1099  Academic         2017       Reddit        2012   \n",
       "\n",
       "                                                  query  query_topicID  \\\n",
       "0     ['sleep', 'relax', 'calm', 'night', 'help', 's...              0   \n",
       "1753  ['anyone_else', 'today', 'amount', 'coffee', '...              1   \n",
       "221   ['drive', 'tomorrow', 'test', 'exercise', 'app...              2   \n",
       "660   ['guy', 'deal', 'one', 'interested', 'random',...              3   \n",
       "1099  ['alone', 'exist', 'somewhere', 'female', 'pre...              4   \n",
       "\n",
       "                                             best_match  best_match_score  \\\n",
       "0     ['patient', 'anxiety', 'cognitive', 'treatment...          0.761707   \n",
       "1753  ['cognitive', 'trait', 'performance', 'avoidan...          0.618855   \n",
       "221   ['phobia', 'life_event', 'depression', 'emerge...          0.711446   \n",
       "660   ['social', 'sad', 'change', 'personality', 'co...          0.564091   \n",
       "1099  ['mental', 'health', 'self', 'network', 'repor...          0.609496   \n",
       "\n",
       "      best_match_topicID  \n",
       "0                      8  \n",
       "1753                   9  \n",
       "221                    8  \n",
       "660                    8  \n",
       "1099                  17  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"Journal_vs_Reddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
