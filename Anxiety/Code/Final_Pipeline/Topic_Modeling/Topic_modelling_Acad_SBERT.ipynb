{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smriti/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Basic Libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import sys\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "#import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "from topic_model_function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "df=pd.read_csv('/home/smriti/Smriti/MITACS/Anxiety/Data/CSV/Academic/Acad_2020.csv')\n",
    "#getting rid of NaN\n",
    "df=df.replace(np.nan, '', regex=True)\n",
    "#Combining title and text\n",
    "df[\"Text\"] = df[\"Title\"] + df[\"Abstract\"]\n",
    "#Now that we don't need Title or Text, we drop those columns before saving the file\n",
    "df=df.drop(['Title', 'Abstract'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoreId</th>\n",
       "      <th>documentType</th>\n",
       "      <th>year</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2445966824.0</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>2020</td>\n",
       "      <td>Threat rapidly disrupts reward reversal learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2445966027.0</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>2020</td>\n",
       "      <td>Fear in the context of pain: Lessons learned f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2445965242.0</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>2020</td>\n",
       "      <td>The effects of positive interpretation bias on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2435222091.0</td>\n",
       "      <td>Evidence Based Healthcare , Journal Article</td>\n",
       "      <td>2020</td>\n",
       "      <td>Implementation and effectiveness of adolescent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2445966078.0</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>2020</td>\n",
       "      <td>The effects of age and trait anxiety on avoida...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        StoreId                                  documentType  year  \\\n",
       "0  2445966824.0                               Journal Article  2020   \n",
       "1  2445966027.0                               Journal Article  2020   \n",
       "2  2445965242.0                               Journal Article  2020   \n",
       "3  2435222091.0   Evidence Based Healthcare , Journal Article  2020   \n",
       "4  2445966078.0                               Journal Article  2020   \n",
       "\n",
       "                                                Text  \n",
       "0  Threat rapidly disrupts reward reversal learni...  \n",
       "1  Fear in the context of pain: Lessons learned f...  \n",
       "2  The effects of positive interpretation bias on...  \n",
       "3  Implementation and effectiveness of adolescent...  \n",
       "4  The effects of age and trait anxiety on avoida...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data=df.Text.values.tolist()\n",
    "# Remove new line characters\n",
    "data=[re.sub('\\s+', ' ', sent) for sent in data]\n",
    "# Remove distracting single quotes\n",
    "data=[re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clean up text\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['threat', 'rapidly', 'disrupts', 'reward', 'reversal', 'learningthreat', 'changes', 'cognition', 'and', 'facilitates', 'adaptive', 'coping', 'however', 'when', 'threat', 'becomes', 'overwhelming', 'it', 'may', 'be', 'deleterious', 'to', 'mental', 'health', 'especially', 'for', 'vulnerable', 'individuals', 'flexible', 'decision', 'making', 'was', 'probed', 'with', 'reward', 'reversal', 'task', 'to', 'investigate', 'how', 'well', 'healthy', 'participants', 'can', 'adapt', 'to', 'changes', 'in', 'reward', 'contingency', 'when', 'they', 'expect', 'adverse', 'events', 'electric', 'shocks', 'in', 'comparison', 'to', 'safe', 'control', 'condition', 'the', 'threat', 'of', 'shock', 'significantly', 'impaired', 'reward', 'reversal', 'learning', 'moreover', 'enhanced', 'self', 'reported', 'threat', 'ratings', 'and', 'elevated', 'skin', 'conductance', 'levels', 'support', 'the', 'successful', 'induction', 'of', 'stressful', 'and', 'aversive', 'apprehensions', 'the', 'findings', 'are', 'in', 'line', 'with', 'literature', 'showing', 'the', 'stress', 'induced', 'inhibition', 'of', 'goal', 'directed', 'behavior', 'at', 'the', 'advantage', 'of', 'reflexive', 'habitual', 'response', 'style', 'notably', 'reversal', 'learning', 'was', 'rapidly', 'restored', 'with', 'the', 'omission', 'of', 'threat', 'through', 'several', 'cycles', 'of', 'threat', 'and', 'safety', 'contexts', 'within', 'one', 'experimental', 'session', 'these', 'results', 'extend', 'the', 'literature', 'and', 'illuminate', 'the', 'immediate', 'consequence', 'of', 'sustained', 'threatening', 'stressor', 'and', 'its', 'removal', 'on', 'decision', 'making', 'better', 'knowledge', 'of', 'the', 'immediate', 'effects', 'of', 'anticipatory', 'anxiety', 'on', 'behavior', 'could', 'improve', 'understanding', 'of', 'psychopathology', 'and', 'may', 'be', 'informative', 'for', 'the', 'development', 'of', 'effective', 'therapy', 'for', 'anxiety', 'and', 'emotion', 'dysregulation']]\n"
     ]
    }
   ],
   "source": [
    "#Clean up text\n",
    "data_words=list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram=gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram=gensim.models.Phrases(bigram[data_words], threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod=gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod=gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['threat', 'rapidly', 'disrupts', 'reward', 'reversal', 'learningthreat', 'changes', 'cognition', 'and', 'facilitates', 'adaptive', 'coping', 'however', 'when', 'threat', 'becomes', 'overwhelming', 'it', 'may', 'be', 'deleterious', 'to', 'mental', 'health', 'especially', 'for', 'vulnerable', 'individuals', 'flexible', 'decision_making', 'was', 'probed', 'with', 'reward', 'reversal', 'task', 'to', 'investigate', 'how', 'well', 'healthy', 'participants', 'can', 'adapt', 'to', 'changes', 'in', 'reward', 'contingency', 'when', 'they', 'expect', 'adverse_events', 'electric', 'shocks', 'in', 'comparison', 'to', 'safe', 'control', 'condition', 'the', 'threat', 'of', 'shock', 'significantly', 'impaired', 'reward', 'reversal', 'learning', 'moreover', 'enhanced', 'self', 'reported', 'threat', 'ratings', 'and', 'elevated', 'skin_conductance', 'levels', 'support', 'the', 'successful', 'induction', 'of', 'stressful', 'and', 'aversive', 'apprehensions', 'the', 'findings', 'are', 'in', 'line', 'with', 'literature', 'showing', 'the', 'stress', 'induced', 'inhibition', 'of', 'goal_directed', 'behavior', 'at', 'the', 'advantage', 'of', 'reflexive', 'habitual', 'response', 'style', 'notably', 'reversal', 'learning', 'was', 'rapidly', 'restored', 'with', 'the', 'omission', 'of', 'threat', 'through', 'several', 'cycles', 'of', 'threat', 'and', 'safety', 'contexts', 'within', 'one', 'experimental', 'session', 'these', 'results', 'extend', 'the', 'literature', 'and', 'illuminate', 'the', 'immediate', 'consequence', 'of', 'sustained', 'threatening', 'stressor', 'and', 'its', 'removal', 'on', 'decision_making', 'better', 'knowledge', 'of', 'the', 'immediate', 'effects', 'of', 'anticipatory', 'anxiety', 'on', 'behavior', 'could', 'improve', 'understanding', 'of', 'psychopathology', 'and', 'may', 'be', 'informative', 'for', 'the', 'development', 'of', 'effective', 'therapy', 'for', 'anxiety', 'and', 'emotion', 'dysregulation']\n"
     ]
    }
   ],
   "source": [
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['threat', 'rapidly', 'disrupt', 'reward', 'reversal', 'learningthreat', 'change', 'cognition', 'facilitate', 'adaptive', 'cope', 'however', 'threat', 'become', 'overwhelming', 'deleterious', 'mental', 'health', 'especially', 'vulnerable', 'individual', 'flexible', 'decision_making', 'probe', 'reward', 'reversal', 'task', 'investigate', 'well', 'healthy', 'participant', 'adapt', 'change', 'reward', 'contingency', 'expect', 'adverse_event', 'electric', 'shock', 'comparison', 'safe', 'control', 'condition', 'threat', 'shock', 'significantly', 'impair', 'reward', 'reversal', 'learn', 'moreover', 'enhanced', 'self', 'report', 'threat', 'rating', 'elevate', 'level', 'support', 'successful', 'induction', 'stressful', 'aversive', 'apprehension', 'finding', 'line', 'literature', 'show', 'stress', 'induce', 'inhibition', 'goal_directe', 'behavior', 'advantage', 'reflexive', 'habitual', 'response', 'style', 'notably', 'reversal', 'learning', 'rapidly', 'restore', 'omission', 'threat', 'several', 'cycle', 'threat', 'safety', 'context', 'experimental', 'session', 'result', 'extend', 'literature', 'illuminate', 'immediate', 'consequence', 'sustain', 'threaten', 'stressor', 'removal', 'decision_make', 'well', 'knowledge', 'immediate', 'effect', 'anticipatory', 'anxiety', 'behavior', 'improve', 'understand', 'psychopathology', 'informative', 'development', 'effective', 'therapy', 'anxiety', 'emotion', 'dysregulation']]\n",
      "There are 1570 unique words in the dictionary, 1570 remain after filtering out lest frequent.\n",
      "1569 remain after filtering out most commonly used words based on tfidf scores.\n"
     ]
    }
   ],
   "source": [
    "#----- CHANGED ------#\n",
    "\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 1. Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "print(data_lemmatized[:1])\n",
    "\n",
    "# 2. Create Dictionary needed for topic modelling\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# 3. Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# 4. Term Document Frequency and Create a bag of words\n",
    "bow_corpus = bow(dictionary=id2word, processed_docs=texts)\n",
    "\n",
    "# 5. Calculate low_tfidf_words\n",
    "# Keep only words with tfidf ranking <= x * len(dictionary)\n",
    "x = 0.2\n",
    "total_word_count, DictDocFreq = tf_df(bow_corpus, id2word)\n",
    "sorted_TFIDF = sort_tfidf(bow_corpus, total_word_count, DictDocFreq)\n",
    "low_tfidf_words = get_low_tfidf_words(x, id2word, sorted_TFIDF)\n",
    "\n",
    "# 6. Filter out least frequently used words\n",
    "no_below = 0.01\n",
    "keep_n = 10000\n",
    "dict_least_freq_filtered = filter_least_frequent(id2word, texts, \n",
    "                                                 no_below, keep_n)\n",
    "\n",
    "# 7. Filter out most commonly used words (i.e. words with low TF-IDF score)\n",
    "dict_tfidf_filtered = filter_most_common(dict_least_freq_filtered, low_tfidf_words)\n",
    "\n",
    "# 8. Create the second bag of words - bow_corpus_TFIDFfiltered, \n",
    "# created after least frequently and most commonly used words were filtered out.\n",
    "corpus = bow(dict_tfidf_filtered, texts)\n",
    "\n",
    "# View\n",
    "[[(dict_tfidf_filtered[id], freq) for id, freq in cp] for cp in corpus[:1]]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dict_tfidf_filtered,\n",
    "                                           num_topics=18,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.048*\"scale\" + 0.026*\"measure\" + 0.024*\"score\" + 0.023*\"gad\" + '\n",
      "  '0.022*\"item\" + 0.022*\"age\" + 0.021*\"assess\" + 0.018*\"analysis\" + '\n",
      "  '0.018*\"factor\" + 0.015*\"sex\"'),\n",
      " (1,\n",
      "  '0.052*\"risk\" + 0.036*\"factor\" + 0.033*\"association\" + 0.024*\"limitation\" + '\n",
      "  '0.017*\"early\" + 0.016*\"associate\" + 0.016*\"ptsd\" + 0.015*\"follow\" + '\n",
      "  '0.015*\"psychiatric\" + 0.014*\"datum\"'),\n",
      " (2,\n",
      "  '0.074*\"covid\" + 0.032*\"psychological\" + 0.030*\"ci\" + 0.030*\"pandemic\" + '\n",
      "  '0.029*\"prevalence\" + 0.023*\"stress\" + 0.020*\"factor\" + 0.017*\"impact\" + '\n",
      "  '0.017*\"survey\" + 0.017*\"high\"'),\n",
      " (3,\n",
      "  '0.030*\"sleep\" + 0.023*\"effect\" + 0.020*\"response\" + 0.014*\"increase\" + '\n",
      "  '0.013*\"network\" + 0.013*\"change\" + 0.012*\"level\" + 0.012*\"time\" + '\n",
      "  '0.012*\"suggest\" + 0.011*\"brain\"'),\n",
      " (4,\n",
      "  '0.091*\"woman\" + 0.075*\"depressive\" + 0.067*\"student\" + 0.064*\"pregnancy\" + '\n",
      "  '0.051*\"year\" + 0.034*\"medical\" + 0.025*\"high\" + 0.025*\"ci\" + '\n",
      "  '0.024*\"perinatal\" + 0.023*\"stressor\"'),\n",
      " (5,\n",
      "  '0.071*\"treatment\" + 0.048*\"intervention\" + 0.032*\"group\" + 0.031*\"therapy\" '\n",
      "  '+ 0.027*\"week\" + 0.022*\"participant\" + 0.021*\"post\" + 0.020*\"follow\" + '\n",
      "  '0.020*\"change\" + 0.020*\"trial\"'),\n",
      " (6,\n",
      "  '0.196*\"distress\" + 0.127*\"psychological\" + 0.061*\"cope\" + 0.053*\"worker\" + '\n",
      "  '0.044*\"vulnerability\" + 0.039*\"transdiagnostic\" + 0.034*\"resilience\" + '\n",
      "  '0.033*\"staff\" + 0.032*\"pain\" + 0.025*\"medical\"'),\n",
      " (7,\n",
      "  '0.144*\"patient\" + 0.037*\"clinical\" + 0.027*\"high\" + 0.026*\"compare\" + '\n",
      "  '0.020*\"depressive\" + 0.020*\"non\" + 0.017*\"associate\" + 0.016*\"score\" + '\n",
      "  '0.015*\"severity\" + 0.014*\"characteristic\"'),\n",
      " (8,\n",
      "  '0.046*\"alcohol\" + 0.043*\"family\" + 0.033*\"loneliness\" + 0.023*\"share\" + '\n",
      "  '0.022*\"people\" + 0.019*\"case\" + 0.017*\"report\" + 0.016*\"community\" + '\n",
      "  '0.015*\"question\" + 0.015*\"error\"'),\n",
      " (9,\n",
      "  '0.184*\"cognitive\" + 0.051*\"trait\" + 0.043*\"performance\" + 0.040*\"avoidance\" '\n",
      "  '+ 0.039*\"face\" + 0.037*\"interpersonal\" + 0.036*\"ability\" + '\n",
      "  '0.026*\"alteration\" + 0.024*\"mediator\" + 0.023*\"skill\"'),\n",
      " (10,\n",
      "  '0.198*\"mdd\" + 0.069*\"suicide\" + 0.059*\"major_depressive\" + 0.050*\"suicidal\" '\n",
      "  '+ 0.038*\"suicidality\" + 0.037*\"scale\" + 0.035*\"rating\" + 0.031*\"indicator\" '\n",
      "  '+ 0.029*\"level\" + 0.025*\"prevalence\"'),\n",
      " (11,\n",
      "  '0.118*\"group\" + 0.066*\"childhood\" + 0.062*\"bipolar\" + 0.041*\"high\" + '\n",
      "  '0.040*\"bd\" + 0.039*\"ocd\" + 0.038*\"youth\" + 0.037*\"age\" + 0.033*\"control\" + '\n",
      "  '0.030*\"abuse\"'),\n",
      " (12,\n",
      "  '0.047*\"negative\" + 0.047*\"self\" + 0.038*\"relationship\" + 0.037*\"individual\" '\n",
      "  '+ 0.025*\"positive\" + 0.024*\"effect\" + 0.021*\"emotion\" + 0.020*\"support\" + '\n",
      "  '0.018*\"measure\" + 0.016*\"predict\"'),\n",
      " (13,\n",
      "  '0.244*\"stress\" + 0.127*\"fear\" + 0.119*\"insomnia\" + 0.040*\"dass\" + '\n",
      "  '0.036*\"sensitivity\" + 0.035*\"environmental\" + 0.033*\"human\" + '\n",
      "  '0.024*\"older_adult\" + 0.021*\"pathological\" + 0.020*\"cause\"'),\n",
      " (14,\n",
      "  '0.272*\"social\" + 0.172*\"adolescent\" + 0.039*\"sad\" + 0.035*\"impulsivity\" + '\n",
      "  '0.031*\"substance\" + 0.029*\"eat\" + 0.029*\"profile\" + 0.028*\"depressive\" + '\n",
      "  '0.021*\"clinical\" + 0.021*\"functional_connectivity\"'),\n",
      " (15,\n",
      "  '0.061*\"health\" + 0.059*\"mental\" + 0.019*\"child\" + 0.018*\"report\" + '\n",
      "  '0.017*\"experience\" + 0.016*\"problem\" + 0.011*\"people\" + 0.011*\"care\" + '\n",
      "  '0.010*\"life\" + 0.010*\"age\"'),\n",
      " (16,\n",
      "  '0.041*\"disability\" + 0.034*\"review\" + 0.030*\"quality\" + 0.027*\"include\" + '\n",
      "  '0.025*\"physical\" + 0.024*\"search\" + 0.020*\"evidence\" + 0.017*\"term\" + '\n",
      "  '0.017*\"implementation\" + 0.016*\"practice\"'),\n",
      " (17,\n",
      "  '0.110*\"treatment\" + 0.049*\"severity\" + 0.038*\"antidepressant\" + '\n",
      "  '0.037*\"functional\" + 0.032*\"psychiatric\" + 0.031*\"drug\" + 0.031*\"meta\" + '\n",
      "  '0.029*\"predict\" + 0.026*\"adult\" + 0.024*\"outcome\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.393260939353818\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.35345393129538905\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 18\n",
    "topic_words = []\n",
    "for i in range(num_topics):\n",
    "    tt = lda_model.get_topic_terms(i,10)\n",
    "    topic_words.append([id2word[pair[0]] for pair in tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scale', 'measure', 'score', 'gad', 'item', 'age', 'assess', 'analysis', 'factor', 'sex']\n",
      "['risk', 'factor', 'association', 'limitation', 'early', 'associate', 'ptsd', 'follow', 'psychiatric', 'datum']\n",
      "['covid', 'psychological', 'ci', 'pandemic', 'prevalence', 'stress', 'factor', 'impact', 'survey', 'high']\n",
      "['sleep', 'effect', 'response', 'increase', 'network', 'change', 'level', 'time', 'suggest', 'brain']\n",
      "['woman', 'depressive', 'student', 'pregnancy', 'year', 'medical', 'high', 'ci', 'perinatal', 'stressor']\n",
      "['treatment', 'intervention', 'group', 'therapy', 'week', 'participant', 'post', 'follow', 'change', 'trial']\n",
      "['distress', 'psychological', 'cope', 'worker', 'vulnerability', 'transdiagnostic', 'resilience', 'staff', 'pain', 'medical']\n",
      "['patient', 'clinical', 'high', 'compare', 'depressive', 'non', 'associate', 'score', 'severity', 'characteristic']\n",
      "['alcohol', 'family', 'loneliness', 'share', 'people', 'case', 'report', 'community', 'question', 'error']\n",
      "['cognitive', 'trait', 'performance', 'avoidance', 'face', 'interpersonal', 'ability', 'alteration', 'mediator', 'skill']\n",
      "['mdd', 'suicide', 'major_depressive', 'suicidal', 'suicidality', 'scale', 'rating', 'indicator', 'level', 'prevalence']\n",
      "['group', 'childhood', 'bipolar', 'high', 'bd', 'ocd', 'youth', 'age', 'control', 'abuse']\n",
      "['negative', 'self', 'relationship', 'individual', 'positive', 'effect', 'emotion', 'support', 'measure', 'predict']\n",
      "['stress', 'fear', 'insomnia', 'dass', 'sensitivity', 'environmental', 'human', 'older_adult', 'pathological', 'cause']\n",
      "['social', 'adolescent', 'sad', 'impulsivity', 'substance', 'eat', 'profile', 'depressive', 'clinical', 'functional_connectivity']\n",
      "['health', 'mental', 'child', 'report', 'experience', 'problem', 'people', 'care', 'life', 'age']\n",
      "['disability', 'review', 'quality', 'include', 'physical', 'search', 'evidence', 'term', 'implementation', 'practice']\n",
      "['treatment', 'severity', 'antidepressant', 'functional', 'psychiatric', 'drug', 'meta', 'predict', 'adult', 'outcome']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,18):\n",
    "    print(topic_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "      <th>Topic_ID</th>\n",
       "      <th>Most_freq_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Year, Source, Topic_ID, Most_freq_words]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Year':[],'Source':[],'Topic_ID':[],'Most_freq_words':[]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Most_freq_words']=topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.assign(Year='2020')\n",
    "df = df.assign(Source='Academic')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[]\n",
    "for i in range(0,18):\n",
    "    ls.append(i)\n",
    "df['Topic_ID']=ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "      <th>Topic_ID</th>\n",
       "      <th>Most_freq_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>Academic</td>\n",
       "      <td>0</td>\n",
       "      <td>[scale, measure, score, gad, item, age, assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>Academic</td>\n",
       "      <td>1</td>\n",
       "      <td>[risk, factor, association, limitation, early,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>Academic</td>\n",
       "      <td>2</td>\n",
       "      <td>[covid, psychological, ci, pandemic, prevalenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>Academic</td>\n",
       "      <td>3</td>\n",
       "      <td>[sleep, effect, response, increase, network, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>Academic</td>\n",
       "      <td>4</td>\n",
       "      <td>[woman, depressive, student, pregnancy, year, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year    Source  Topic_ID                                    Most_freq_words\n",
       "0  2020  Academic         0  [scale, measure, score, gad, item, age, assess...\n",
       "1  2020  Academic         1  [risk, factor, association, limitation, early,...\n",
       "2  2020  Academic         2  [covid, psychological, ci, pandemic, prevalenc...\n",
       "3  2020  Academic         3  [sleep, effect, response, increase, network, c...\n",
       "4  2020  Academic         4  [woman, depressive, student, pregnancy, year, ..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"topic_words_j2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
